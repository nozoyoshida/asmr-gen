# `README.md`と現状実装のギャップ分析と今後の実装プラン

## 1. `README.md`とのギャップ分析

`README.md`で描かれている理想的なアーキテクチャと、現在の実装状況を比較した結果、以下の4つの主要なギャップが確認された。

| 機能要素 | `README.md` (理想) | 現状の実装 | ギャップ |
| :--- | :--- | :--- | :--- |
| **1. 脚本生成** | 話者(`speaker`)と台詞(`script`)を分離した**JSON形式**で出力。 | `script_agent`が**プレーンテキスト形式**で出力。 | **出力形式の不一致** |
| **2. 音声生成** | JSON形式の脚本に基づき、各パートの音声を生成。 | `tts_agent`が単一のテキストから**モノラル音声**を生成。 | 空間演出の概念がない |
| **3. 空間演出プランニング** | 専門エージェントが脚本を分析し、音の定位や残響を定義した**JSONキーフレーム**を生成。 | **未実装** | **機能自体が欠落** |
| **4. ASMR化 (バイノーラル)** | 専門エージェントがモノラル音声と空間演出プランを元に、HRTF処理等を施し**バイノーラル音声**を生成。 | **未実装** | **機能自体が欠落** |
| **5. 依存ライブラリ** | `spaudiopy`, `pedalboard` 等の音声処理ライブラリを使用。 | `requirements.txt` に記載がなく、インストールされていない。 | **環境の不備** |
| **6. 全体ワークフロー** | 4つのエージェントが連携するマルチエージェントシステム。 | 2つのエージェント(`script` -> `tts`)を直列に実行するのみ。 | **アーキテクチャの単純化** |

**結論として、現状は「テキストでの脚本生成」と「モノラル音声の合成」という基本的な機能のみが実装されており、`README.md`の根幹をなす「AIによる動的な空間演出」と「バイノーラル音声化」の機能が完全に欠落している状態です。**

---

## 2. 今後の実装プラン

上記のギャップを解消し、`README.md`で定義されたアプリケーションを完成させるための実装プランを以下に提案します。

### Step 1: 依存関係の追加

ASMR化処理に必須の音声処理ライブラリをプロジェクトに追加します。

-   **タスク**: `requirements.txt` に以下のライブラリを追加し、`pip install -r requirements.txt` を実行する。
    -   `spaudiopy`
    -   `pedalboard`
    -   `numpy`
    -   `soundfile` (音声ファイルの読み書き用)

### Step 2: 脚本生成エージェントの修正 (`script_agent.py`)

出力をプレーンテキストからJSON形式に変更します。

-   **タスク**: `script_agent` のプロンプト (`instruction`) を修正し、`README.md`に記載されているJSONスキーマ通りの出力を生成するように指示を変更します。
-   **出力キー**: `output_key` を `script_text` から `script_json` に変更します。

### Step 3: 【新規】空間演出プラン生成エージェントの作成 (`spatial_plan_agent.py`)

ASMR-GENのコア機能である、空間演出プランを生成するエージェントを新規に作成します。

-   **ファイル**: `asmr_gen_adk/agents/spatial_plan_agent.py` を新規作成します。
-   **入力**: `script_json`, **モノラル音声ファイルのパス**
-   **処理**: Gemini 2.5 Pro (Multi-modal) を利用し、脚本の文脈と、**実際の音声のタイミング（間やポーズ）**の両方を解釈して、`README.md`記載のキーフレーム形式（`time`, `azimuth`, `distance` 等を含むJSON配列）で空間演出プランを出力するプロンプトを設計します。
-   **出力**: `spatial_plan_json`

### Step 4: 【新規】ASMR化エージェント（ツール）の作成 (`binaural_renderer.py`)

モノラル音声をバイノーラル化する音声処理ツールと、それを呼び出すエージェントを作成します。

-   **ファイル**: `asmr_gen_adk/tools/binaural_renderer.py` を新規作成し、音声処理ロジックを実装します。
    -   **入力**: モノラル音声ファイルのパス、`spatial_plan_json`
    -   **処理**:
        1.  `soundfile`で音声を読み込み。
        2.  `spatial_plan_json` のキーフレーム間を `numpy` で補間し、滑らかなパラメータ変化を生成。
        3.  `spaudiopy` を用いて、補間されたパラメータに基づきHRTF処理を適用。
        4.  `pedalboard` を用いて、リバーブ処理を適用。
        5.  処理後のバイノーラル音声（2ch WAV）をファイルに出力。
    -   **出力**: バイノーラル音声ファイルのパス
-   **ファイル**: `asmr_gen_adk/agents/asmr_agent.py` を新規作成し、上記ツールを呼び出す`LlmAgent`を定義します。

### Step 5: 音声生成エージェントの修正 (`tts_agent.py`)

JSON形式の脚本から、読み上げるべきテキストを抽出するように修正します。

-   **タスク**: `_build_instruction` 関数を修正し、入力される `script_json` から `main character` の `script` のみを抽出・連結してTTSの入力とするように変更します。

### Step 6: 全体ワークフローの再構築 (`agent.py`)

`README.md`のフロー図に沿ったワークフローに再構築します。

-   **タスク**: `SequentialAgent` を使用して、以下の処理フローを実装します。
    1.  `script_agent` を実行し、脚本(JSON)を生成。
    2.  `tts_agent` を実行し、モノラル音声(WAV)を生成。
    3.  `spatial_plan_agent` を実行し、脚本と音声を基に空間演出プラン(JSON)を生成。
    4.  `asmr_agent` を実行し、モノラル音声と空間演出プランを基に最終的なバイノーラル音声(WAV)を生成。
